# -*- coding: utf-8 -*-
"""lab_4b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ap41HmOrjqBDMMhzu3w1rXjFxFmCARvY

# LAB Session 4b (20/12/2020)

You will generate the Higgs mass spectrum, with signal and background, and perform fits to binned data. Then you can repeat the generation to emulate multiple experiments and perform some statistical analysis.

This notebook provides guidance to obtain a correct spectrum and fit it. At the end you will find a few questions to answer (by repeating some of the steps and making some plots).

The main steps are:
- Generate Gaussian signal
 - plot the distribution
- Generate exponential background
 - plot the distribution 
- Plot the distribution of data by stacking signal and background
- Obtain binned data from histogram
- Fit binned data with `curve_fit`
- Compute the signal significance defined as $S/\sqrt B$

At this point you can repeat the steps above to perform a few studies and make some plots, as asked for at the end of the notebook.

# Modules for this exercise

- `scipy.optimize` for fitting
- `scipy.integrate` for integration
"""

import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
from scipy import optimize as opt  
from scipy import integrate

"""# Parameters
- Number of signal events
- Number of background events
- Higgs mass
- Higgs width due to detector resolution (intrinsic width is negligible)
"""

n_sig_0 = 100
n_bkg_0 = 10000

m_sig = 125 # GeV
w_sig = 0.02 # in %
w_sig *= m_sig

"""# Histogram data
Boundaries and number of bins
"""

x_min = 0    # GeV
x_max = 200  # GeV
n_bins = 100
bin_width = (x_max-x_min)/n_bins # GeV
print('%d bins from %.1f to %.1f GeV' % (n_bins, x_min, x_max))
print('Bin width: %.2f GeV' % (bin_width))

"""## Generate signal sample

`n_sig_0` events with a Gaussian distribution around Higgs mass
"""

s=np.random.normal(m_sig,w_sig,n_sig_0)

"""## Plots signal distribution

Use [matplotlib.pyplot.hist](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.hist.html)
"""

# Commented out IPython magic to ensure Python compatibility.
#%matplotlib notebook
# %matplotlib inline 

n,bins,patches=plt.hist(s,bins=n_bins,label='gaussian data')
plt.legend()
plt.grid()
plt.show()

"""## Generate background sample

`n_bkg_0` events with an exponential distribution. Use [numpy.random.exponential](https://numpy.org/doc/stable/reference/random/generated/numpy.random.exponential.html).

Choose an exponential parameter that populates bins with tens of events for mass of 200 GeV. For example, use `scale=80` in [numpy.random.exponential].
"""

e=np.random.exponential(80,n_bkg_0)

"""## Plots background distribution
Use [matplotlib.pyplot.hist](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.hist.html)

Useful options:
- _bins=n_ : fix number of bins to _n_
- _hist=options_ : for example _hist='step'_ to show empty histogram
- _range=(min,max)_ : fix the boundaries of data in histogram. 
  - **NB**: this is different than using _xlim(min,max)_ which is only for visualization

"""

n,bins,patches=plt.hist(e,bins=n_bins,label='background',range=(0,200),facecolor='green')
plt.show()

"""## Stack signal and background data in the same histogram

If you have two data arrays `signal` and `background`, the following can stack `signal` on top of the `background`

```python
plt.hist((background, signal), bins=n_bins, label=('backgroud', 'signal'),
         color=('red', 'blue'), stacked=True, 
         histtype='step', range=(x_min, x_max))
```
"""

plt.hist((e, s), bins=n_bins, label=('backgroud', 'signal'),
         color=('red', 'blue'), stacked=True, 
         histtype='step', range=(0, 200))

"""## Merge signal and background samples

The data collected in an experiment contains both signal and background. Two samples separately stored in NumPy arrays can be merged with [numpy.concatenate](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) as follows:

```python
data = np.concatenate((a,b))
```
with the first positional argument of the function being a tuple of numpy arrays.
"""

data=np.concatenate((e,s))

"""## Binned data

The data sample so far is unbinned: we have a number of signal and background events. 

Now we can create a binned version to be fitted. This is achieved with the `pyplot.hist` function which, as we saw, returns a list of counts for each bin and the bin boundaries
```python
binned_data, bins, _ = plt.hist(data, bins=n_bins, label='all data', color='black', histtype='step', range=(x_min, x_max))

```

Plot the merged data and make sure it is indeed the sum of the two sub-samples.
"""

binned_data, bins, _ = plt.hist(data, bins=n_bins, label='all data', color='black', histtype='step', range=(x_min, x_max))

"""## `bins` list

The list `bins` contains `n_bins + 1` values. These are run from the edge of the first bin to the edge of the last bin. Verify this.
"""

print(len(bins))

"""## Center of bins (data along $x$ axis)

Using a comprehension, prepare a list `center_bins` from `bins` with length of `n_bins` which contains the center of each bin of the histogram. Check your result.
"""

central_bins=[0.5*(bins[i+1]+bins[i]) for i in range(len(bins)-1)]
print(type(central_bins))

"""## Bin count (data along $y$ axis)

Verify that the list `binned data` has length `n_bins`.
"""

print(len(central_bins))

"""## Fitting the histogram

We want to fit the binned data (`binned_data` as a function of `center_bins`) using the [optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) function.

The fit model has to be the sum of a Gaussian and an exponential.

Define three functions with proper arguments
1. `sig(x, Norm, mean, width)` for the signal Gaussian
2. `bkg(x, Norm, alpha)` for the background exponential
3. `total(x, NormSig, mean, width, NormBkg, alpha)` sum of signal and background

There is a total of 5 parameters to be fitted from the simulated data.
"""

def sig(x,Normsig,mean,width):
    return Normsig*np.exp(-((x-mean)*(x-mean))/(2*width*width))

def bkg(x,Normbkg,alpha):
    return Normbkg*alpha*np.exp(-alpha*x)

def total(x,Normsig,mean,width,Normbkg,alpha):
    return sig(x,Normsig,mean,width)+bkg(x,Normbkg,alpha)

def seno(x,a):
    return np.sin(a*x)

"""## Plot fit function

As a sanity check, plot the 3 functions and make sure they are implemented correctly.
"""

t=np.arange(300)
y=total(t,1,50,1,1,0.5)
plt.plot(y)
q=sig(t,1,50,1)
plt.plot(q)

"""## Initial conditions for the fit

It is always a good practice to provide some initial values for the parameters to be fitted, especially in a case like this one where there are 5 parameters and the data varies a lot across the spectrum. Initial values are passed to [optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) with the argument `p0`:
```python
pars, pars_cov = opt.curve_fit(..., p0=[500, m_sig, w_sig, 1000, alpha])
```

Recall that `pars` is the list of fitted parameters (in the order they appear in the definition of the fit function) and `pars_cov` is their covariance matrix that can be used to compute the uncertainty on each fitted parameter.
"""

pars, pars_cov = opt.curve_fit(total,central_bins,n,p0=[3.13, m_sig, w_sig, 19970,0.0125])

"""## Fitted parameters
- Print the parameters
- Print the covariance matrix

Are the fitted values close to the generated values?
"""

print(pars)
print('\n')
print(pars_cov)

"""## Plot the histogram and fit

- Plot the data histogram
- Overlay the fitted function (`total`) with the fitted parameters
- Overlay the background function with the fitted parameters
- Print the fitted parameters with proper legend on the screen
"""

x_plot=np.arange(500)
plt
plt.plot(x_plot,total(x_plot,*pars),label='fit',color='red')
binned_data, bins, _ = plt.hist(data, bins=n_bins, label='all data', color='green', histtype='step', range=(x_min, x_max))
n,bins,patches=plt.hist(e,bins=n_bins,label='background',range=(0,200),facecolor='blue')
plt.xlim(0,205)
plt.legend()

"""# Signal Significance

The signal significance is defined as

$$
S/\sqrt{B}\,,
$$

where

$$
\begin{align}
S &= \int_a^b sig(m)\, dm\\
B &= \int_a^b bkg(m)\, dm
\end{align}
$$

with $a = m_{\rm fitted} - 3\sigma_{\rm fitted}$ and $b = m_{\rm fitted} + 3\sigma_{\rm fitted}$.

Use [scipy.integrate.quad](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html) to compute the integral.

The result of a call to `scipy.integrate.quad` is a list with two elements:
1. the value of the integral
1. its uncertainty

## Compute $S$
"""

S=lambda x: sig(x,3.13,m_sig,w_sig)
s=integrate.quad(S,126-3*0.53,126+3*0.53)

"""## Compute $B$"""

B=lambda x: bkg(x,19970,0.0125)
b=integrate.quad(B,126-3*0.53,126+3*0.53)

"""## Compute significance and print the result"""

print(s)
print(b)
Significance=s[0]/np.sqrt(b[0])
print("The significance value: ",Significance)

"""# Exercise 1

1. Fix the number of background events $N_B = 10000$ and vary the number of signal events $N_S$ in 
 `[10, 50, 100, 500, 1000]`
  - Plot the signficance as a function of $N_S$
  - You can now change $N_B$ and generate the same plot and show the data for different values of $N_B$
  - How does the significance depend on $N_S$ and $N_B$?
"""



"""# Exercise 2

2. Fix $N_B = 10000$ and $N_S = 200$. Vary the mass width in `[0.01, 0.2, 0.05, 0.10, 0.20, 0.50]`
  - Plot the significance as a function of the mass width 
  - Which mass width provide the best signal significance?
"""



"""# Exercise 3


3. Fix $N_B = 10000$ and $N_S = 200$ and repeat the experiments 1000 times
  - For each experiment generate the number of signal and background events from a Poisson distribution
    - mean of signal events: 200
    - mean of background events: 10000
  - Compute the significance for each experiment
  - Plot the distribution of significance for all experiments
  - Plot the distribution of $m_{fitted} - m_H$ for all experiments
  - Fit to a Gaussian and print the fitted $\mu$ and $\sigma$
"""

